# yt-takeout-extractor

## üìå √úbersicht
Tool zum Importieren von YouTube-History-Daten aus Google Takeout in eine PostgreSQL-Datenbank. Verarbeitet JSON-Daten, extrahiert Video-IDs, validiert Eingaben und vermeidet Duplikate.

## ‚öôÔ∏è Funktionsweise

### Import-Skript (`import_youtube_history.ts`)
```typescript
// Code-Snippet: Validierung mit Zod
const RawYouTubeHistoryEntrySchema = z.object({
  title: z.string().min(1),
  titleUrl: z.string().url(),
  time: z.string().datetime(),
  // ...
});
```

- **Validierung**: Zod-Schema pr√ºft Rohdatenstruktur
- **ID-Extraktion**: Regex-Muster extrahieren YouTube-ID aus URLs
- **Batch-Verarbeitung**: 8 Eintr√§ge pro Batch (optimiert f√ºr Performance)
- **Duplikaterkennung**: `ON CONFLICT`-Klausel √ºberspringt vorhandene Eintr√§ge
- **Fehlerlogging**: Detaillierte Fehlerprotokolle mit Originaldaten

### Datenbank-Schema (`create_youtube_history.sql`)
```sql
CREATE TABLE IF NOT EXISTS youtube_history (
    youtube_id VARCHAR(20) NOT NULL,
    watched_time TIMESTAMP NOT NULL,
    -- ...
    UNIQUE (youtube_id, watched_time)
);
```

- **Tabellenstruktur**:
  - `youtube_id`: Video-Identifier (20 Zeichen)
  - `watched_time`: Exakter Wiedergabezeitpunkt
  - `activity_controls`: JSONB f√ºr YouTube-Interaktionen
- **Indizes**:
  - `watched_time DESC`: Schnelle Zeitbereichsabfragen
  - `youtube_id`: Video-spezifische Suche
  - GIN-Index f√ºr JSON-Daten

## Import Youtube Note Links

**Ablauf:**

Das Skript erh√§lt einen Ordnerpfad als Kommandozeilenargument und findet alle Markdown-Dateien darin. F√ºr jede Datei extrahiert es die erste H1-√úberschrift als Titel und sucht nach Markdown-Links im Format `[URL](http://...)`. Nur Links mit dem Label "URL" werden ber√ºcksichtigt.

Jeder gefundene Link wird validiert: Ist es keine YouTube-URL, wird ein Fehler geloggt. Bei g√ºltigen YouTube-URLs wird die Video-ID extrahiert (unterst√ºtzt verschiedene URL-Formate wie `youtube.com/watch?v=...`, `youtu.be/...`, `embed`).

Die extrahierten Daten (YouTube-ID, Titel, Dateipfad) werden per Zod-Schema validiert und in die Datenbank eingef√ºgt. Dabei wird gepr√ºft: Existiert der Eintrag bereits identisch (ID + Titel + Datei), wird dies als Info geloggt. Existiert die ID mit anderem Titel, gilt dies als Fehler.

**Fehlerbehandlung:**

Das Skript bricht bei Fehlern nicht ab, sondern z√§hlt sie mit. Am Ende erfolgt eine Zusammenfassung mit Anzahl neuer Eintr√§ge und Fehler. Der Exit-Code signalisiert, ob Fehler auftraten (1) oder nicht (0).

Die Implementierung ist rein funktional ohne objektorientierte Konstrukte und nutzt `zod`, `pg` und `dotenv`.

## üìã Voraussetzungen
- Node.js ‚â•18.x
- PostgreSQL ‚â•15
- `.env`-Datei mit:
  ```env
  DATABASE_URL="postgres://user:pass@host:port/db"
  ```

## üõ†Ô∏è Installation
```bash
bun install
cd packages/yt-takeout-extractor
cp .env.example .env
dotenv -f .env run -- zsh
psql $DATABASE_URL -f src/create_youtube_history.sql
psql $DATABASE_URL -f src/create_youtube_note_links.sql
psql $DATABASE_URL -f src/create_youtube_transcript.sql
```

## üöÄ Verwendung
```bash
bun src/import_youtube_history.ts watched.json
```

## üíª Beispielausgabe
```
Verarbeite 542 validierte Eintr√§ge in Batches √† 8...
Batch 1: 8 erfolgreich, 0 Fehler, 2 Duplikate
Batch 2: 6 erfolgreich, 2 Fehler, 0 Duplikate
...
========== Zusammenfassung ==========
Erfolgreich importiert: 521
Duplikate √ºbersprungen: 15
Fehler: 6
```

## üóÉÔ∏è Datenbankschema-Dokumentation
| Spalte | Typ | Beschreibung |
|--------|-----|--------------|
| id | SERIAL | Prim√§rschl√ºssel |
| title | TEXT | Videotitel |
| youtube_id | VARCHAR(20) | Eindeutige YouTube-Video-ID |
| watched_time | TIMESTAMP | Exakter Wiedergabezeitpunkt |
| details | JSONB | Zus√§tzliche Metadaten |
| activity_controls | JSONB | Nutzerinteraktionen (z.B. "Watched", "Search") |

## üö® Fehlerbehandlung
- **Validierungsfehler**:
  - Protokolliert ung√ºltige JSON-Strukturen
  - Speichert fehlerhafte Rohdaten zur Analyse
- **Datenbankfehler**:
  - Transaktionsrollback bei Batch-Fehlern
  - Isolierte Fehler pro Eintrag (kein Abbruch)
- **Logging**:
  - Konsolenausgabe mit Fehlerstatistiken
  - Detailierte Originaldaten bei schweren Fehlern